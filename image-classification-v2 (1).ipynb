{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport timm\nimport tqdm\nimport sys\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom datetime import datetime \nimport numpy as np\n\n\"\"\"\nCIFAR10:\n- 32x32 colour image\n- 60000 training\n- 10000 testing\n- ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] classes\n\"\"\"\n\n#手动定义参数类，专门存储训练的参数，\nclass cfg(object):\n  pass\n\nclass args(object):\n  pass\n\nargs.epochs = 40\nargs.batch_size = 32\nargs.model = 'resnet50'\nargs.learning_rate = 0.01\nargs.path = '/Users/lixu/Desktop/llm-notes/neural_network/data'\ncfg.valid_loss = np.array([])\n\nmodel = timm.create_model(args.model, pretrained=True,num_classes=10)\ndevice = torch.device(\"cpu\")\nmodel.to(device)\ntrain_dataset = torchvision.datasets.CIFAR10(root = args.path,\n                                              train = True,\n                                                  transform = transforms.Compose([\n#                                                           transforms.Resize((32,32)),\n                                                          transforms.ToTensor(),\n                                                          transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n                                                  download = True)\n\n# train_dataset, val_dataset = torch.utils.data.random_split(row_dataset, [40000, 10000])\n\n\ntest_dataset = torchvision.datasets.CIFAR10(root = args.path,\n                                                  train = False,\n                                                  transform = transforms.Compose([\n#                                                           transforms.Resize((32,32)),\n                                                  transforms.ToTensor(),\n                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),)\n\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                           batch_size = args.batch_size,\n                                           shuffle = True)\n\n\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                          batch_size = args.batch_size,\n                                          shuffle = True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T12:58:40.068744Z","iopub.execute_input":"2024-05-10T12:58:40.069217Z","iopub.status.idle":"2024-05-10T12:59:04.229386Z","shell.execute_reply.started":"2024-05-10T12:58:40.069183Z","shell.execute_reply":"2024-05-10T12:59:04.227011Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"174fa3d4834947a892ef6ca2f443f0ac"}},"metadata":{}},{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /Users/lixu/Desktop/llm-notes/neural_network/data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:08<00:00, 20547048.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /Users/lixu/Desktop/llm-notes/neural_network/data/cifar-10-python.tar.gz to /Users/lixu/Desktop/llm-notes/neural_network/data\n","output_type":"stream"}]},{"cell_type":"code","source":"# plot the validation loss\ncfg.valid_loss = np.array([])\ndef display_loss(cfg, data):\n    if len(cfg.valid_loss) == 0:\n        cfg.valid_loss = np.array([data])\n        x, y = cfg.valid_loss.T\n        plt.scatter(x,y)\n        plt.show()\n    else:\n        cfg.valid_loss = np.concatenate([cfg.valid_loss, np.array([data])])\n        x, y = cfg.valid_loss.T\n        plt.plot(x,y)\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T09:13:19.109730Z","iopub.execute_input":"2024-05-08T09:13:19.110099Z","iopub.status.idle":"2024-05-08T09:13:19.118426Z","shell.execute_reply.started":"2024-05-08T09:13:19.110068Z","shell.execute_reply":"2024-05-08T09:13:19.115749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(),args.learning_rate)\n\n\n# 0: loading existing model parameters\n# model.load_state_dict(torch.load(args.path)\n# model.eval()\n\n\nprint('start training')\ntotal_step = len(train_loader)\navg_vloss = 0\nbest_vloss = 0\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\nepoch_number = 0\nbest_vloss = 1_000_000.\n\nfor epoch in range(args.epochs):\n    \n    # 1. Per epoch\n    for i, (images, labels) in enumerate(train_loader):  \n        images = images.to(device)\n        labels = labels.to(device)\n        model.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        \n        if (i+1) % 100 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n                   .format(epoch+1, args.epochs, i+1, total_step, loss.item()))\n    print('end one traning epoch')\n\n    \n    # 2. validation: Disable gradient computation and reduce memory consumption.\n    avg_vloss = 0.0\n    with torch.no_grad():\n        correct = 0\n        total = 0\n\n        for images, labels in test_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            avg_vloss += loss.item()\n    print('Training vs. Validation Loss',\n            { 'Training' : best_vloss, 'Validation' : avg_vloss/len(test_loader) },\n            epoch_number + 1)\n    \n    display_loss(cfg, [epoch_number, avg_vloss/len(test_loader)])\n\n#             _, predicted = torch.max(outputs.data, 1)\n#             total += labels.size(0)\n#             correct += (predicted == labels).sum().item()\n        \n        \n    # 3. Track best performance, and save the model's state\n    avg_vloss = avg_vloss /len(test_loader) / (epoch_number + 1)\n    if avg_vloss < best_vloss:\n        best_vloss = avg_vloss\n        model_path = args.path + '/model_{}_{}'.format(timestamp, epoch_number)\n        print(\"store at {}\".format(model_path))\n        torch.save(model.state_dict(), model_path)\n        \n    \n    # 4. epoch loop, ref: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n    epoch_number += 1\n\nprint('end training')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T09:13:19.119617Z","iopub.execute_input":"2024-05-08T09:13:19.119941Z","iopub.status.idle":"2024-05-08T09:16:05.719674Z","shell.execute_reply.started":"2024-05-08T09:13:19.119915Z","shell.execute_reply":"2024-05-08T09:16:05.718824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\n\n# These are just example labels\ny_true = [0, 1, 1, 0, 1, 1]\ny_pred = [0, 0, 1, 1, 1, 1]\n\n# Accuracy\naccuracy = metrics.accuracy_score(y_true, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Precision\nprecision = metrics.precision_score(y_true, y_pred)\nprint(f'Precision: {precision}')\n\n# Recall\nrecall = metrics.recall_score(y_true, y_pred)\nprint(f'Recall: {recall}')\n\n# F1 Score\nf1 = metrics.f1_score(y_true, y_pred)\nprint(f'F1 Score: {f1}')","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:05:19.443304Z","iopub.execute_input":"2024-05-09T12:05:19.443670Z","iopub.status.idle":"2024-05-09T12:05:20.986985Z","shell.execute_reply.started":"2024-05-09T12:05:19.443644Z","shell.execute_reply":"2024-05-09T12:05:20.985497Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Accuracy: 0.6666666666666666\nPrecision: 0.75\nRecall: 0.75\nF1 Score: 0.75\n","output_type":"stream"}]},{"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    total = 0\n\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n    \n        print(outputs[0])\n        print(labels)\n        break\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-10T12:59:55.324959Z","iopub.execute_input":"2024-05-10T12:59:55.325702Z","iopub.status.idle":"2024-05-10T12:59:55.680688Z","shell.execute_reply.started":"2024-05-10T12:59:55.325652Z","shell.execute_reply":"2024-05-10T12:59:55.679279Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"tensor([-0.0811, -0.0645,  0.0974, -0.0639,  0.3708, -0.1186, -0.0487, -0.3961,\n         0.0347,  0.0164])\ntensor([5, 4, 8, 8, 7, 6, 1, 6, 7, 5, 5, 8, 8, 9, 7, 5, 3, 9, 7, 4, 2, 0, 8, 0,\n        9, 0, 6, 3, 7, 2, 8, 7])\n","output_type":"stream"}]}]}